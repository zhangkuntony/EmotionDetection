# æƒ…ç»ªè¯†åˆ«ç³»ç»Ÿ (Emotion Detection System)

åŸºäºæ·±åº¦å­¦ä¹ çš„é¢éƒ¨è¡¨æƒ…è¯†åˆ«ç³»ç»Ÿï¼Œä½¿ç”¨æ”¹è¿›çš„VGGNetæ¶æ„è¿›è¡Œæƒ…ç»ªåˆ†ç±»ã€‚

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªå®Œæ•´çš„äººè„¸æƒ…ç»ªè¯†åˆ«æµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
- æ•°æ®é¢„å¤„ç†å’Œå¢å¼º
- æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒ
- æ¨¡å‹è¯„ä¼°å’Œæµ‹è¯•
- å¯è§†åŒ–å’Œç›‘æ§

## ğŸ¯ ç‰¹æ€§

- **å¤šç§æƒ…ç»ªç±»åˆ«æ”¯æŒ**ï¼šæ”¯æŒ6ç±»æˆ–7ç±»æƒ…ç»ªè¯†åˆ«
- **æ”¹è¿›çš„VGGNetæ¶æ„**ï¼šé’ˆå¯¹å°å°ºå¯¸é¢éƒ¨å›¾åƒä¼˜åŒ–
- **æ•°æ®å¢å¼ºç­–ç•¥**ï¼šæé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›
- **è®­ç»ƒç›‘æ§**ï¼šå®æ—¶ç›‘æ§è®­ç»ƒè¿‡ç¨‹å’Œæ¨¡å‹æ€§èƒ½
- **æ¨¡å‹æ£€æŸ¥ç‚¹**ï¼šä¿å­˜å’Œæ¢å¤è®­ç»ƒçŠ¶æ€

## ğŸ“ é¡¹ç›®ç»“æ„

```
EmotionDetection/
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ build_dataset.py          # æ•°æ®é›†æ„å»ºè„šæœ¬
â”‚   â”œâ”€â”€ train_recognizer.py      # æ¨¡å‹è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ test_recognizer.py       # æ¨¡å‹æµ‹è¯•è„šæœ¬
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ emotion_config.py    # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ pyimage/
â”‚   â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ callbacks/
â”‚   â”‚   â”œâ”€â”€ io/
â”‚   â”‚   â””â”€â”€ nn/conv/
â”‚   â””â”€â”€ dataset/
â”‚       â””â”€â”€ fer2013.csv          # FER-2013æ•°æ®é›†
â”œâ”€â”€ checkpoints/                # æ¨¡å‹æ£€æŸ¥ç‚¹ç›®å½•
â”œâ”€â”€ hdf5/                     # å¤„ç†åçš„æ•°æ®é›†
â””â”€â”€ output/                   # è®­ç»ƒè¾“å‡ºå’Œå¯è§†åŒ–
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

å®‰è£…å¿…è¦çš„ä¾èµ–ï¼š
```bash
pip install tensorflow numpy matplotlib h5py pandas
```

### 2. æ•°æ®å‡†å¤‡

æ„å»ºHDF5æ•°æ®é›†ï¼š
```bash
cd code
python build_dataset.py
```

æ­¤å‘½ä»¤ä¼šï¼š
- è§£æFER-2013æ•°æ®é›†
- åˆ†ç¦»è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†
- åº”ç”¨æ ‡ç­¾æ˜ å°„ï¼ˆ6ç±»æ¨¡å¼ä¼šåˆå¹¶angerå’Œdisgustï¼‰
- ä¿å­˜ä¸ºHDF5æ ¼å¼
- æ˜¾ç¤ºæ•°æ®åˆ†å¸ƒç»Ÿè®¡

### 3. æ¨¡å‹è®­ç»ƒ

ä»å¤´å¼€å§‹è®­ç»ƒï¼š
```bash
python train_recognizer.py --checkpoints checkpoints
```

ä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒï¼š
```bash
python train_recognizer.py --checkpoints checkpoints --model checkpoints/epoch_25.hdf5 --start-epoch 25
```

### 4. æ¨¡å‹è¯„ä¼°

æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹ï¼š
```bash
python test_recognizer.py --model checkpoints/epoch_50.hdf5
```

## âš™ï¸ é…ç½®é€‰é¡¹

### æ•°æ®é…ç½® (`config/emotion_config.py`)

```python
# ç±»åˆ«æ•°é‡ (6æˆ–7)
NUM_CLASSES = 6  # åˆå¹¶angerå’Œdisgust

# æ‰¹é‡å¤§å°
BATCH_SIZE = 64

# æ•°æ®é›†è·¯å¾„
TRAIN_HDF5 = "./hdf5/train.hdf5"
VAL_HDF5 = "./hdf5/val.hdf5"
TEST_HDF5 = "./hdf5/test.hdf5"
```

### è®­ç»ƒå‚æ•°

- **åˆå§‹å­¦ä¹ ç‡**ï¼š1e-4
- **æ•°æ®å¢å¼º**ï¼šæ—‹è½¬ã€å¹³ç§»ã€ç¼©æ”¾ã€å‰ªåˆ‡ã€ç¿»è½¬
- **å­¦ä¹ ç‡è°ƒåº¦**ï¼šReduceLROnPlateau (éªŒè¯å‡†ç¡®ç‡ç›‘æ§)
- **æ—©åœç­–ç•¥**ï¼š20è½®éªŒè¯å‡†ç¡®ç‡æ— æå‡åˆ™åœæ­¢

## ğŸ§  æ¨¡å‹æ¶æ„

æ”¹è¿›çš„VGGNetæ¶æ„ï¼Œä¸“ä¸ºé¢éƒ¨è¡¨æƒ…è¯†åˆ«ä¼˜åŒ–ï¼š

```
Input: 48Ã—48Ã—1 ç°åº¦å›¾åƒ
â”œâ”€â”€ Block #1: Conv(64) â†’ ELU â†’ BatchNorm â†’ Conv(64) â†’ ELU â†’ BatchNorm â†’ MaxPool â†’ Dropout
â”œâ”€â”€ Block #2: Conv(64) â†’ ELU â†’ BatchNorm â†’ Conv(64) â†’ ELU â†’ BatchNorm â†’ MaxPool â†’ Dropout
â”œâ”€â”€ Block #3: Conv(128) â†’ ELU â†’ BatchNorm â†’ Conv(128) â†’ ELU â†’ BatchNorm â†’ MaxPool â†’ Dropout
â”œâ”€â”€ FC #1: Dense(256) â†’ ELU â†’ BatchNorm â†’ Dropout
â”œâ”€â”€ FC #2: Dense(128) â†’ ELU â†’ BatchNorm â†’ Dropout
â””â”€â”€ Output: Dense(NUM_CLASSES) â†’ Softmax
```

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

è®­ç»ƒå¥½çš„æ¨¡å‹åœ¨FER-2013æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½ï¼š

| æ¨¡å‹ | è®­ç»ƒå‡†ç¡®ç‡ | éªŒè¯å‡†ç¡®ç‡ | æµ‹è¯•å‡†ç¡®ç‡ |
|-------|-------------|-------------|-----------|
| VGGNet (6ç±») | ~68% | ~64% | ~62% |
| VGGNet (7ç±») | ~65% | ~60% | ~58% |

## ğŸ”§ è‡ªå®šä¹‰å’Œæ‰©å±•

### æ·»åŠ æ–°çš„æ•°æ®å¢å¼º

åœ¨ `train_recognizer.py` ä¸­ä¿®æ”¹ `ImageDataGenerator` å‚æ•°ï¼š

```python
train_aug = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.15,
    height_shift_range=0.15,
    zoom_range=0.2,
    horizontal_flip=True,
    shear_range=0.1,
    fill_mode="nearest",
    rescale=1/255.0
)
```

### ä¿®æ”¹æ¨¡å‹æ¶æ„

ç¼–è¾‘ `pyimage/nn/conv/emotionvggnet.py` ä¸­çš„ `build()` æ–¹æ³•ï¼š

```python
@staticmethod
def build(width, height, depth, classes):
    model = Sequential()
    # æ·»åŠ è‡ªå®šä¹‰å±‚...
    return model
```

### è°ƒæ•´è®­ç»ƒè¶…å‚æ•°

ä¿®æ”¹ `train_recognizer.py` ä¸­çš„è®­ç»ƒå‚æ•°ï¼š

```python
# å­¦ä¹ ç‡
opt = Adam(learning_rate=1e-4)

# è®­ç»ƒè½®æ¬¡
epochs = 100

# å›è°ƒå‡½æ•°
reduce_lr = ReduceLROnPlateau(
    monitor='val_accuracy',
    factor=0.7,
    patience=3,
    min_lr=1e-6
)
```

## ğŸ› å¸¸è§é—®é¢˜

### 1. è®­ç»ƒå‡†ç¡®ç‡ä½

**å¯èƒ½åŸå› **ï¼š
- è®­ç»ƒè½®æ¬¡ä¸è¶³ï¼ˆè‡³å°‘50è½®ï¼‰
- æ•°æ®å¢å¼ºä¸å¤Ÿ
- å­¦ä¹ ç‡ä¸åˆé€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# å¢åŠ è®­ç»ƒè½®æ¬¡
epochs = 100

# å¢å¼ºæ•°æ®å¢å¼º
rotation_range=20
zoom_range=0.2

# æ·»åŠ å­¦ä¹ ç‡è°ƒåº¦
reduce_lr = ReduceLROnPlateau(...)
```

### 2. å†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**ï¼š
- å‡å°æ‰¹é‡å¤§å°ï¼š`BATCH_SIZE = 32`
- å‡å°æ¨¡å‹è§„æ¨¡
- ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯

### 3. è¿‡æ‹Ÿåˆ

**è§£å†³æ–¹æ¡ˆ**ï¼š
- å¢åŠ Dropoutç‡ï¼š0.25 â†’ 0.5
- æ·»åŠ æ›´å¤šæ•°æ®å¢å¼º
- ä½¿ç”¨æ—©åœç­–ç•¥

## ğŸ“ˆ å¯è§†åŒ–å’Œç›‘æ§

è®­ç»ƒè¿‡ç¨‹ä¼šç”Ÿæˆä»¥ä¸‹å¯è§†åŒ–æ–‡ä»¶ï¼š

- `output/vggnet_emotion.png`ï¼šè®­ç»ƒ/éªŒè¯å‡†ç¡®ç‡å’ŒæŸå¤±æ›²çº¿
- `output/vggnet_emotion.json`ï¼šè¯¦ç»†çš„è®­ç»ƒå†å²
- `checkpoints/epoch_XX.hdf5`ï¼šæ¨¡å‹æ£€æŸ¥ç‚¹

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Forkæœ¬é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æ‰“å¼€Pull Request

## ğŸ“œ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ™ è‡´è°¢

- [FER-2013æ•°æ®é›†](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge)
- Keraså’ŒTensorFlowç¤¾åŒº
- æ‰€æœ‰è´¡çŒ®è€…å’Œç”¨æˆ·

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. Goodfellow, I. J., et al. "Challenges in Representation Learning: A report on three machine learning contests." *Neural Information Processing Systems*, 2013.
2. Li, S. & Deng, W. "Deep facial expression recognition: A survey." *Neurocomputing*, 2020.

---

**Happy coding! ğŸ‰**